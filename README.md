# EigenFace
This is an implementation of the EigenFace algorithm from scratch. The code is based on the [original paper on EigenFace](http://www.face-rec.org/algorithms/pca/jcn.pdf).

## Modules required:
1. python (3.x)
2. pandas (>0.24.2)
3. sklearn (>0.20.3)
4. opencv (>3.4.2)

The main **EigenFace** class is defined in the *face_recognition.py*.

Class functions in **EigenFace**:
1. generateLabels : Generates a dataframe from a folder of images. The dataframe consists of url/path to the image in the 1st column and the label (name of the directory) in the 2nd column.
2. readLabels : Separates the 1st and 2nd columns as X and y and returns them.
3. saveModel : Saves the created model locally for future use.
5. loadModel : Loads the saved model.
6. fit : If mode is "train", it trains a new model, and if mode is "load", it loads pre-existing model.
7. image_predict : Returns the prediction for provided image.
8. predict : Returns the prediction for dataframe (of the form generated by *generateLabels*).

The recognition is completed in 2 phases. First, there is the detection part which has been attained by the use of *haarcascade* classifier. It has its own limitation but that is beyond the scope of our project. Second is the recognition part which is done by the EigenFace algorithm. 

To run the code with default settings, you'll need to keep a directory (say *Example*). *Example* should contain folders inside it. Each folder should consist of images of a single person and the name of the folder should be set to the name of that individual (or any other unique id). So, if I have 5 individual's photos (say *A*, *B*, *C*, *D* and *E*), the *Example* folder would look something like this:

```
Example
    |
    |-- A
    |   |- image_1
    |   |- image_2
    |   |- image_n
    |
    |-- B
    |   |- image_1
    |   |- image_n
    |
    |-- C
    |   |- image_1
    |   |- image_n
    |
    |-- D
    |   |- image_1
    |   |- image_n
    |
    |-- E
        |- image_1
        |- image_n

```
A sample code for training and saving a model can be found in *train_model.py*, and a sample code for recognition can be found in *make_prediction.py*.

Optionally, *extract_face.py* can be used to crop the faces from the structured directory (as aforementioned) before feeding it to the model for training for better results. 

-----

Coming up:
1. Prediction from saved videos
2. Multiple face recognition from a single frame
